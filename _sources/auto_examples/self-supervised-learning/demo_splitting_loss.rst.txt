
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_examples/self-supervised-learning/demo_splitting_loss.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        New to DeepInverse? Get started with the basics with the
        :ref:`5 minute quickstart tutorial <sphx_glr_auto_examples_basics_demo_quickstart.py>`.

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_examples_self-supervised-learning_demo_splitting_loss.py:


Self-supervised learning with measurement splitting
===================================================

We demonstrate self-supervised learning with measurement splitting, to
train a denoiser network on the MNIST dataset. The physics here is noisy
computed tomography, as is the case in Noise2Inverse :footcite:t:`hendriksen2020noise2inverse`. Note this example
can also be easily applied to undersampled multicoil MRI as is the case
in SSDU :footcite:t:`yaman2020self`.

Measurement splitting constructs a ground-truth free loss
:math:`\frac{m}{m_2}\| y_2 - A_2 \inversef{y_1}{A_1}\|^2` by splitting
the measurement and the forward operator using a randomly generated
mask.

See :class:`deepinv.loss.SplittingLoss` for full details.

.. GENERATED FROM PYTHON SOURCE LINES 19-38

.. code-block:: Python


    from pathlib import Path

    import torch
    from torch.utils.data import DataLoader
    from torchvision import transforms, datasets

    import deepinv as dinv
    from deepinv.utils.demo import get_data_home
    from deepinv.models.utils import get_weights_url

    torch.manual_seed(0)
    device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else "cpu"

    BASE_DIR = Path(".")
    DATA_DIR = BASE_DIR / "measurements"
    ORIGINAL_DATA_HOME = get_data_home()









.. GENERATED FROM PYTHON SOURCE LINES 39-61

Define loss
~~~~~~~~~~~

Our implementation has multiple optional parameters that control how the
splitting is to be achieved. For example, you can:

-  Use ``split_ratio`` to set the ratio of pixels used in the forward
   pass vs the loss;
-  Define custom masking methods using a ``mask_generator`` such as
   :class:`deepinv.physics.generator.BernoulliSplittingMaskGenerator`
   or :class:`deepinv.physics.generator.GaussianSplittingMaskGenerator`;
-  Use ``eval_n_samples`` to set how many realisations of the random
   mask is used at evaluation time;
-  Optionally disable measurement splitting at evaluation time using
   ``eval_split_input`` (as is the case in SSDU :footcite:t:`yaman2020self`).
-  Average over both input and output masks at evaluation time using
   ``eval_split_output``. See :class:`deepinv.loss.SplittingLoss` for
   details.

Note that after the model has been defined, the loss must also "adapt"
the model.


.. GENERATED FROM PYTHON SOURCE LINES 61-65

.. code-block:: Python


    loss = dinv.loss.SplittingLoss(split_ratio=0.6, eval_split_input=True, eval_n_samples=5)









.. GENERATED FROM PYTHON SOURCE LINES 66-78

Prepare data
~~~~~~~~~~~~

We use the ``torchvision`` MNIST dataset, and use noisy tomography
physics (with number of angles equal to the image size) for the forward
operator.

.. note::

     We use a subset of the whole training set to reduce the computational load of the example.
     We recommend to use the whole set by setting ``train_datapoints=test_datapoints=None`` to get the best results.


.. GENERATED FROM PYTHON SOURCE LINES 78-112

.. code-block:: Python


    transform = transforms.Compose([transforms.ToTensor()])

    train_dataset = datasets.MNIST(
        root=ORIGINAL_DATA_HOME, train=True, transform=transform, download=True
    )
    test_dataset = datasets.MNIST(
        root=ORIGINAL_DATA_HOME, train=False, transform=transform, download=True
    )

    physics = dinv.physics.Tomography(
        angles=28,
        img_width=28,
        noise_model=dinv.physics.noise.GaussianNoise(0.1),
        device=device,
    )

    deepinv_datasets_path = dinv.datasets.generate_dataset(
        train_dataset=train_dataset,
        test_dataset=test_dataset,
        physics=physics,
        device=device,
        save_dir=DATA_DIR,
        train_datapoints=100,
        test_datapoints=10,
    )

    train_dataset = dinv.datasets.HDF5Dataset(path=deepinv_datasets_path, train=True)
    test_dataset = dinv.datasets.HDF5Dataset(path=deepinv_datasets_path, train=False)

    train_dataloader = DataLoader(train_dataset, shuffle=True)
    test_dataloader = DataLoader(test_dataset, shuffle=False)






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Dataset has been saved at measurements/dinv_dataset0.h5




.. GENERATED FROM PYTHON SOURCE LINES 113-127

Define model
~~~~~~~~~~~~

We use a simple U-Net architecture with 2 scales as the denoiser
network.

To reduce training time, we use a pretrained model. Here we demonstrate
training with 100 images for 1 epoch, after having loaded a pretrained
model trained that was with 1000 images for 20 epochs.

.. note::

     When using the splitting loss, the model must be "adapted" by the loss, as its forward pass takes only a subset of the pixels, not the full image.


.. GENERATED FROM PYTHON SOURCE LINES 127-146

.. code-block:: Python


    model = dinv.models.ArtifactRemoval(
        dinv.models.UNet(in_channels=1, out_channels=1, scales=2).to(device), pinv=True
    )
    model = loss.adapt_model(model)

    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-8)

    # Load pretrained model
    file_name = "demo_measplit_mnist_tomography.pth"
    url = get_weights_url(model_name="measplit", file_name=file_name)
    ckpt = torch.hub.load_state_dict_from_url(
        url, map_location=lambda storage, loc: storage, file_name=file_name
    )

    model.load_state_dict(ckpt["state_dict"])
    optimizer.load_state_dict(ckpt["optimizer"])






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Downloading: "https://huggingface.co/deepinv/measplit/resolve/main/demo_measplit_mnist_tomography.pth?download=true" to /home/runner/.cache/torch/hub/checkpoints/demo_measplit_mnist_tomography.pth
      0%|          | 0.00/5.13M [00:00<?, ?B/s]    100%|██████████| 5.13M/5.13M [00:00<00:00, 234MB/s]




.. GENERATED FROM PYTHON SOURCE LINES 147-150

Train and test network
----------------------


.. GENERATED FROM PYTHON SOURCE LINES 150-169

.. code-block:: Python


    trainer = dinv.Trainer(
        model=model,
        physics=physics,
        epochs=1,
        losses=loss,
        optimizer=optimizer,
        device=device,
        train_dataloader=train_dataloader,
        plot_images=False,
        save_path=None,
        verbose=True,
        show_progress_bar=False,
        no_learning_method="A_dagger",  # use pseudo-inverse as no-learning baseline
    )

    model = trainer.train()






.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    The model has 444737 trainable parameters
    /home/runner/work/deepinv/deepinv/deepinv/loss/measplit.py:273: UserWarning: Mask generator not defined. Using new Bernoulli mask generator.
      warn("Mask generator not defined. Using new Bernoulli mask generator.")
    /home/runner/work/deepinv/deepinv/deepinv/physics/forward.py:814: UserWarning: At least one input physics is a DecomposablePhysics, but resulting physics will not be decomposable. `A_dagger` and `prox_l2` will fall back to approximate methods, which may impact performance.
      warnings.warn(
    Train epoch 0: TotalLoss=0.032, PSNR=28.999




.. GENERATED FROM PYTHON SOURCE LINES 170-174

Test and visualize the model outputs using a small test set. We set the
output to average over 5 iterations of random mask realisations. The
trained model improves on the no-learning reconstruction by ~7dB.


.. GENERATED FROM PYTHON SOURCE LINES 174-179

.. code-block:: Python


    trainer.plot_images = True
    trainer.test(test_dataloader)





.. image-sg:: /auto_examples/self-supervised-learning/images/sphx_glr_demo_splitting_loss_001.png
   :alt: Ground truth, No learning, Reconstruction
   :srcset: /auto_examples/self-supervised-learning/images/sphx_glr_demo_splitting_loss_001.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Eval epoch 0: PSNR=31.157, PSNR no learning=24.549
    Test results:
    PSNR no learning: 24.549 +- 1.052
    PSNR: 31.157 +- 2.742

    {'PSNR no learning': np.float64(24.548789978027344), 'PSNR no learning_std': np.float64(1.0523070216572739), 'PSNR': np.float64(31.157159423828126), 'PSNR_std': np.float64(2.741690328412059)}



.. GENERATED FROM PYTHON SOURCE LINES 180-184

Demonstrate the effect of not averaging over multiple realisations of
the splitting mask at evaluation time, by setting ``eval_n_samples=1``.
We have a worse performance:


.. GENERATED FROM PYTHON SOURCE LINES 184-189

.. code-block:: Python


    model.eval_n_samples = 1
    trainer.test(test_dataloader)





.. image-sg:: /auto_examples/self-supervised-learning/images/sphx_glr_demo_splitting_loss_002.png
   :alt: Ground truth, No learning, Reconstruction
   :srcset: /auto_examples/self-supervised-learning/images/sphx_glr_demo_splitting_loss_002.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Eval epoch 0: PSNR=29.164, PSNR no learning=24.549
    Test results:
    PSNR no learning: 24.549 +- 1.052
    PSNR: 29.164 +- 2.453

    {'PSNR no learning': np.float64(24.548789978027344), 'PSNR no learning_std': np.float64(1.0523070216572739), 'PSNR': np.float64(29.163711547851562), 'PSNR_std': np.float64(2.45347311299908)}



.. GENERATED FROM PYTHON SOURCE LINES 190-195

Furthermore, we can disable measurement splitting at evaluation
altogether by setting ``eval_split_input`` to False (this is done in
SSDU :footcite:t:`yaman2020self`). This generally is
worse than MC averaging:


.. GENERATED FROM PYTHON SOURCE LINES 195-199

.. code-block:: Python


    model.eval_split_input = False
    trainer.test(test_dataloader)




.. image-sg:: /auto_examples/self-supervised-learning/images/sphx_glr_demo_splitting_loss_003.png
   :alt: Ground truth, No learning, Reconstruction
   :srcset: /auto_examples/self-supervised-learning/images/sphx_glr_demo_splitting_loss_003.png
   :class: sphx-glr-single-img


.. rst-class:: sphx-glr-script-out

 .. code-block:: none

    Eval epoch 0: PSNR=30.966, PSNR no learning=24.549
    Test results:
    PSNR no learning: 24.549 +- 1.052
    PSNR: 30.966 +- 2.493

    {'PSNR no learning': np.float64(24.548789978027344), 'PSNR no learning_std': np.float64(1.0523070216572739), 'PSNR': np.float64(30.966433715820312), 'PSNR_std': np.float64(2.4932139371115007)}



.. GENERATED FROM PYTHON SOURCE LINES 200-203

:References:

.. footbibliography::


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** (0 minutes 9.194 seconds)


.. _sphx_glr_download_auto_examples_self-supervised-learning_demo_splitting_loss.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: demo_splitting_loss.ipynb <demo_splitting_loss.ipynb>`

    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: demo_splitting_loss.py <demo_splitting_loss.py>`

    .. container:: sphx-glr-download sphx-glr-download-zip

      :download:`Download zipped: demo_splitting_loss.zip <demo_splitting_loss.zip>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
